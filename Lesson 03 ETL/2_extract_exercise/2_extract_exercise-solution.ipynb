{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract from JSON and XML\n",
    "\n",
    "You'll now get practice extracting data from JSON and XML. You'll extract the same population data from the previous exercise, except the data will be in a different format.\n",
    "\n",
    "Both JSON and XML are common formats for storing data. XML was established before JSON, and JSON has become more popular over time. They both tend to be used for sending data via web APIs, which you'll learn about later in the lesson.\n",
    "\n",
    "Sometimes, you can obtain the same data in either JSON or XML format. The World Bank indicator data is available in either form. In this exercise, you'll use the same data except one file is formatted as JSON and the other as XML.\n",
    "\n",
    "There is a solution file for these exercises. Go to File->Open and click on 2_extract_exercise_solution.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract JSON and JSON Exercise\n",
    "\n",
    "First, you'll practice extracting data from a JSON file. Run the cell below to print out the first line of the JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "#   Run the following cell.\n",
    "#   This cell loads a function that prints the first n lines of\n",
    "#   a file.\n",
    "#\n",
    "#   Then this function is called on the JSON file to print out\n",
    "#   the first line of the population_data.json file\n",
    "###\n",
    "\n",
    "def print_lines(n, file_name):\n",
    "    f = open(file_name)\n",
    "    for i in range(n):\n",
    "        print(f.readline())\n",
    "    f.close()\n",
    "    \n",
    "print_lines(1, 'population_data.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first \"line\" in the file is actually the entire file. JSON is a compact way of representing data in a dictionary-like format. Luckily, pandas has a method to [read in a json file](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_json.html). \n",
    "\n",
    "If you open the link with the documentation, you'll see there is an *orient* option that can handle JSON formatted in different ways:\n",
    "```\n",
    "'split' : dict like {index -> [index], columns -> [columns], data -> [values]}\n",
    "'records' : list like [{column -> value}, ... , {column -> value}]\n",
    "'index' : dict like {index -> {column -> value}}\n",
    "'columns' : dict like {column -> {index -> value}}\n",
    "'values' : just the values array\n",
    "```\n",
    "\n",
    "In this case, the JSON is formatted with a 'records' orientation, so you'll need to use that value in the read_json() method. You can tell that the format is 'records' by comparing the pattern in the documentation with the pattern in the JSON file.\n",
    "\n",
    "Next, read in the population_data.json file using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Read in the population_data.json file using pandas's \n",
    "# read_json method. Don't forget to specific the orient option\n",
    "# store the rsults in df_json\n",
    "\n",
    "import pandas as pd\n",
    "df_json = pd.read_json('population_data.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use the head method to see the first few rows of the resulting\n",
    "# dataframe\n",
    "df_json.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this population data is the same as the data from the previous exercise. The column order might have changed, but the data is otherwise the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Ways to Read in JSON\n",
    "\n",
    "Besides using pandas to read JSON files, you can use the json library. Run the code cell below to see an example of reading in JSON with the json library. Python treats JSON data like a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# read in the JSON file\n",
    "with open('population_data.json') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "# print the first record in the JSON file\n",
    "print(json_data[0])\n",
    "print('\\n')\n",
    "\n",
    "# show that JSON data is essentially a dictionary\n",
    "print(json_data[0]['Country Name'])\n",
    "print(json_data[0]['Country Code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract XML\n",
    "\n",
    "Next, you'll work with the same data except now the data is in xml format. Run the next code cell to see what the first fifteen lines of the data file look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_lines(15, 'population_data.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XML looks very similar to HTML. XML is formatted with tags having values inside the tags. XML is not as easy to navigate as JSON. Pandas cannot read in XML directly. One reason is that tag names are user defined. Every XML file might have different formatting. You can imagine why XML has fallen out of favor relative to JSON."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to read and navigate XML\n",
    "\n",
    "There is a Python library called BeautifulSoup, which makes reading in and parsing XML data easier. Here is the link to the documentation: [Beautiful Soup Documentation](https://www.crummy.com/software/BeautifulSoup/)\n",
    "\n",
    "The find() method will find the first place where an xml element occurs. For example using find('record') will return the first record in the xml file:\n",
    "\n",
    "```xml\n",
    "<record>\n",
    "  <field name=\"Country or Area\" key=\"ABW\">Aruba</field>\n",
    "  <field name=\"Item\" key=\"SP.POP.TOTL\">Population, total</field>\n",
    "  <field name=\"Year\">1960</field>\n",
    "  <field name=\"Value\">54211</field>\n",
    "</record>\n",
    "```\n",
    "\n",
    "The find_all() method returns all of the matching tags. So find_all('record') would return all of the elements with the `<record>` tag.\n",
    "\n",
    "Run the code cells below to get a basic idea of how to navigate XML with BeautifulSoup. To navigate through the xml file, you search for a specific tag using the find() method or find_all() method. \n",
    "\n",
    "Below these code cells, there is an exercise for wrangling the XML data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the BeautifulSoup library\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# open the population_data.xml file and load into Beautiful Soup\n",
    "with open(\"population_data.xml\") as fp:\n",
    "    soup = BeautifulSoup(fp, \"lxml\") # lxml is the Parser type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country or Area :  Aruba\n",
      "Item :  Population, total\n",
      "Year :  1960\n",
      "Value :  54211\n",
      "\n",
      "Country or Area :  Aruba\n",
      "Item :  Population, total\n",
      "Year :  1961\n",
      "Value :  55438\n",
      "\n",
      "Country or Area :  Aruba\n",
      "Item :  Population, total\n",
      "Year :  1962\n",
      "Value :  56225\n",
      "\n",
      "Country or Area :  Aruba\n",
      "Item :  Population, total\n",
      "Year :  1963\n",
      "Value :  56695\n",
      "\n",
      "Country or Area :  Aruba\n",
      "Item :  Population, total\n",
      "Year :  1964\n",
      "Value :  57032\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# output the first 5 records in the xml file\n",
    "# this is an example of how to navigate with BeautifulSoup\n",
    "\n",
    "i = 0\n",
    "# use the find_all method to get all record tags in the document\n",
    "for record in soup.find_all('record'):\n",
    "    # use the find_all method to get all fields in each record\n",
    "    i += 1\n",
    "    for record in record.find_all('field'):\n",
    "        print(record['name'], ': ' , record.text)\n",
    "    print()\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XML Exercise (Challenge)\n",
    "\n",
    "Create a data frame from the xml file. This exercise is somewhat tricky. One solution would be to convert the xml data into dictionaries and then use the dictionaries to create a data frame. \n",
    "\n",
    "The dataframe should have the following layout:\n",
    "\n",
    "| Country or Area | Year | Item | Value |\n",
    "|----|----|----|----|\n",
    "| Aruba | 1960 | Population, total | 54211 |\n",
    "| Aruba | 1961 | Population, total | 55348 |\n",
    "etc...\n",
    "\n",
    "Technically, extracting XML, transforming the results, and putting it into a data frame is a full ETL pipeline. This exercise is jumping ahead in terms of what's to come later in the lesson. But it's a good chance to familiarize yourself with XML. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a pandas data frame from the XML data.\n",
    "# HINT: You can use dictionaries to create pandas data frames.\n",
    "# HINT: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.from_dict.html#pandas.DataFrame.from_dict\n",
    "# HINT: You can make a dictionary for each column or for each row\n",
    "# HINT: Modify the code from the previous code cell\n",
    "\n",
    "\n",
    "# output the first 5 records in the xml file\n",
    "# this is an example of how to navigate with BeautifulSoup\n",
    "\n",
    "# use the find_all method to get all record tags in the document\n",
    "data_dictionary = {'Country or Area':[], 'Year':[], 'Item':[], 'Value':[]}\n",
    "\n",
    "for record in soup.find_all('record'):\n",
    "    for record in record.find_all('field'):\n",
    "        data_dictionary[record['name']].append(record.text)\n",
    "\n",
    "df = pd.DataFrame.from_dict(data_dictionary)\n",
    "df = df.pivot(index='Country or Area', columns='Year', values='Value')\n",
    "df.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Year</th>\n",
       "      <th>Country or Area</th>\n",
       "      <th>1960</th>\n",
       "      <th>1961</th>\n",
       "      <th>1962</th>\n",
       "      <th>1963</th>\n",
       "      <th>1964</th>\n",
       "      <th>1965</th>\n",
       "      <th>1966</th>\n",
       "      <th>1967</th>\n",
       "      <th>1968</th>\n",
       "      <th>...</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>8996351</td>\n",
       "      <td>9166764</td>\n",
       "      <td>9345868</td>\n",
       "      <td>9533954</td>\n",
       "      <td>9731361</td>\n",
       "      <td>9938414</td>\n",
       "      <td>10152331</td>\n",
       "      <td>10372630</td>\n",
       "      <td>10604346</td>\n",
       "      <td>...</td>\n",
       "      <td>27294031</td>\n",
       "      <td>28004331</td>\n",
       "      <td>28803167</td>\n",
       "      <td>29708599</td>\n",
       "      <td>30696958</td>\n",
       "      <td>31731688</td>\n",
       "      <td>32758020</td>\n",
       "      <td>33736494</td>\n",
       "      <td>34656032</td>\n",
       "      <td>35530081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1608800</td>\n",
       "      <td>1659800</td>\n",
       "      <td>1711319</td>\n",
       "      <td>1762621</td>\n",
       "      <td>1814135</td>\n",
       "      <td>1864791</td>\n",
       "      <td>1914573</td>\n",
       "      <td>1965598</td>\n",
       "      <td>2022272</td>\n",
       "      <td>...</td>\n",
       "      <td>2947314</td>\n",
       "      <td>2927519</td>\n",
       "      <td>2913021</td>\n",
       "      <td>2905195</td>\n",
       "      <td>2900401</td>\n",
       "      <td>2895092</td>\n",
       "      <td>2889104</td>\n",
       "      <td>2880703</td>\n",
       "      <td>2876101</td>\n",
       "      <td>2873457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>11124888</td>\n",
       "      <td>11404859</td>\n",
       "      <td>11690153</td>\n",
       "      <td>11985136</td>\n",
       "      <td>12295970</td>\n",
       "      <td>12626952</td>\n",
       "      <td>12980267</td>\n",
       "      <td>13354197</td>\n",
       "      <td>13744387</td>\n",
       "      <td>...</td>\n",
       "      <td>34860715</td>\n",
       "      <td>35465760</td>\n",
       "      <td>36117637</td>\n",
       "      <td>36819558</td>\n",
       "      <td>37565847</td>\n",
       "      <td>38338562</td>\n",
       "      <td>39113313</td>\n",
       "      <td>39871528</td>\n",
       "      <td>40606052</td>\n",
       "      <td>41318142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>20013</td>\n",
       "      <td>20486</td>\n",
       "      <td>21117</td>\n",
       "      <td>21882</td>\n",
       "      <td>22698</td>\n",
       "      <td>23520</td>\n",
       "      <td>24321</td>\n",
       "      <td>25116</td>\n",
       "      <td>25885</td>\n",
       "      <td>...</td>\n",
       "      <td>57030</td>\n",
       "      <td>56227</td>\n",
       "      <td>55637</td>\n",
       "      <td>55320</td>\n",
       "      <td>55230</td>\n",
       "      <td>55307</td>\n",
       "      <td>55437</td>\n",
       "      <td>55537</td>\n",
       "      <td>55599</td>\n",
       "      <td>55641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>13411</td>\n",
       "      <td>14375</td>\n",
       "      <td>15370</td>\n",
       "      <td>16412</td>\n",
       "      <td>17469</td>\n",
       "      <td>18549</td>\n",
       "      <td>19647</td>\n",
       "      <td>20758</td>\n",
       "      <td>21890</td>\n",
       "      <td>...</td>\n",
       "      <td>83861</td>\n",
       "      <td>84462</td>\n",
       "      <td>84449</td>\n",
       "      <td>83751</td>\n",
       "      <td>82431</td>\n",
       "      <td>80788</td>\n",
       "      <td>79223</td>\n",
       "      <td>78014</td>\n",
       "      <td>77281</td>\n",
       "      <td>76965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Year Country or Area      1960      1961      1962      1963      1964  \\\n",
       "0        Afghanistan   8996351   9166764   9345868   9533954   9731361   \n",
       "1            Albania   1608800   1659800   1711319   1762621   1814135   \n",
       "2            Algeria  11124888  11404859  11690153  11985136  12295970   \n",
       "3     American Samoa     20013     20486     21117     21882     22698   \n",
       "4            Andorra     13411     14375     15370     16412     17469   \n",
       "\n",
       "Year      1965      1966      1967      1968    ...         2008      2009  \\\n",
       "0      9938414  10152331  10372630  10604346    ...     27294031  28004331   \n",
       "1      1864791   1914573   1965598   2022272    ...      2947314   2927519   \n",
       "2     12626952  12980267  13354197  13744387    ...     34860715  35465760   \n",
       "3        23520     24321     25116     25885    ...        57030     56227   \n",
       "4        18549     19647     20758     21890    ...        83861     84462   \n",
       "\n",
       "Year      2010      2011      2012      2013      2014      2015      2016  \\\n",
       "0     28803167  29708599  30696958  31731688  32758020  33736494  34656032   \n",
       "1      2913021   2905195   2900401   2895092   2889104   2880703   2876101   \n",
       "2     36117637  36819558  37565847  38338562  39113313  39871528  40606052   \n",
       "3        55637     55320     55230     55307     55437     55537     55599   \n",
       "4        84449     83751     82431     80788     79223     78014     77281   \n",
       "\n",
       "Year      2017  \n",
       "0     35530081  \n",
       "1      2873457  \n",
       "2     41318142  \n",
       "3        55641  \n",
       "4        76965  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Like CSV, JSON and XML are ways to format data. If everything is formatted correctly, JSON is especially easy to work with. XML is an older standard and a bit trickier to handle.\n",
    "\n",
    "As a reminder, there is a solution file for these exercises. You can go to File->Open and then click on 2_extract_exercise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
